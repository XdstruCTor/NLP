{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XdstruCTor/nlp/blob/master/CFG_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk import CFG\n",
        "nltk.download('treebank')\n",
        "from nltk.tree import Tree\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1c8q8uDhIQS",
        "outputId": "85db2930-e7bc-491d-c6bb-28fedb901896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CKY Parsing Algorithm\n",
        "\n",
        "The CKY (Cocke-Kasami-Younger) algorithm is a bottom-up parsing algorithm used to determine whether a given sentence can be generated by a context-free grammar (CFG) in Chomsky Normal Form (CNF). Here, we implement the CKY algorithm for a sentence and CFG. Briefly the algorithm works by building up parse trees from individual words, combining them into larger subtrees until the entire sentence is parsed.\n",
        "\n",
        "#### 1. **Grammar Definition**\n",
        "\n",
        "CFG in Chomsky Normal Form (CNF):"
      ],
      "metadata": {
        "id": "rOpYMRXKOs_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> A NP\n",
        "  NP -> A N\n",
        "  A -> 'colorless'|'green'\n",
        "  N -> 'ideas'\n",
        "  VP -> V Adv\n",
        "  V -> 'sleep'\n",
        "  Adv -> 'furiously'\n",
        "\"\"\")\n",
        "\n",
        "grammar.chomsky_normal_form()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DjDyJI7gOAO",
        "outputId": "7f6ed5b9-cb3a-40ba-d5c9-a19145adf9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Grammar with 9 productions>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then convert the grammar into CNF by calling grammar.chomsky_normal_form(). since the CKY algorithm works only with grammars in CNF, which means that all rules must either:\n",
        "\n",
        "   - Produce exactly two non-terminal symbols on the right-hand side (A -> B C), or  \n",
        "   - Produce a single terminal symbol (A -> 'terminal')."
      ],
      "metadata": {
        "id": "QWNREnmjO7iV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Flipping the Grammar for CKY Parsing**\n",
        "In CKY, the parsing table needs access to the rules in reverse form (right-hand side as keys). This way, we can easily look up what non-terminal could have produced a given pair of non-terminals. To achieve this, the grammar is flipped:"
      ],
      "metadata": {
        "id": "5jQdz1CvPcLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_flipped_grammar(grammar):\n",
        "  rules = grammar.productions()\n",
        "  flipped_grammar = {}\n",
        "  for rule in rules:\n",
        "    rhs = rule.rhs()\n",
        "    if rhs not in flipped_grammar:\n",
        "      flipped_grammar[rhs] = set()\n",
        "    flipped_grammar[rhs].add(rule.lhs())\n",
        "  return flipped_grammar\n",
        "\n",
        "flipped_grammar = get_flipped_grammar(grammar)\n",
        "for rhs, lhs_set in flipped_grammar.items():\n",
        "    print(f\"{rhs} -> {', '.join(str(lhs) for lhs in lhs_set)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa2xbcw6JEuc",
        "outputId": "dd681e6c-6d28-4cf2-b3b3-651b461fcd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(NP, VP) -> S\n",
            "(A, NP) -> NP\n",
            "(A, N) -> NP\n",
            "('colorless',) -> A\n",
            "('green',) -> A\n",
            "('ideas',) -> N\n",
            "(V, Adv) -> VP\n",
            "('sleep',) -> V\n",
            "('furiously',) -> Adv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Explanation of the CKY function**\n",
        "\n",
        "We initialize a 2D table (`table`) with dimensions (`n+1`) `x` (`n+1`) (where `n` is the number of words in the sentence). Each entry in the table stores a list of possible parse trees that can be derived for a substring of the sentence.\n",
        "   - Then the first step is to fill in the table for `terminals`. For each word in the sentence, we check if it's in the grammar's right-hand side and add the corresponding non-terminal.  \n",
        "     - Next, for each span of words, we try to combine previously computed entries (subtrees) from smaller spans. For each combination of subtrees, we check the grammar to see if they can be combined into a larger subtree\n",
        "\n",
        "Once the table is filled, the possible parse trees for the whole sentence (from the first word to the last) will be stored in table `[0]` `[n]`. then print these trees\n",
        "        "
      ],
      "metadata": {
        "id": "QJHTprdvPvO6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V10mjKwsS9tC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c53cee9-abe2-4f67-dbd9-24d279739aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled table[0][1]: [Tree(A, ['colorless'])]\n",
            "Filled table[1][2]: [Tree(A, ['green'])]\n",
            "Filled table[0][2]: []\n",
            "Filled table[2][3]: [Tree(N, ['ideas'])]\n",
            "Filled table[1][3]: [Tree(NP, [Tree(A, ['green']), Tree(N, ['ideas'])])]\n",
            "Filled table[0][3]: [Tree(NP, [Tree(A, ['colorless']), Tree(NP, [Tree(A, ['green']), Tree(N, ['ideas'])])])]\n",
            "Filled table[3][4]: [Tree(V, ['sleep'])]\n",
            "Filled table[2][4]: []\n",
            "Filled table[1][4]: []\n",
            "Filled table[0][4]: []\n",
            "Filled table[4][5]: [Tree(Adv, ['furiously'])]\n",
            "Filled table[3][5]: [Tree(VP, [Tree(V, ['sleep']), Tree(Adv, ['furiously'])])]\n",
            "Filled table[2][5]: []\n",
            "Filled table[1][5]: [Tree(S, [Tree(NP, [Tree(A, ['green']), Tree(N, ['ideas'])]), Tree(VP, [Tree(V, ['sleep']), Tree(Adv, ['furiously'])])])]\n",
            "Filled table[0][5]: [Tree(S, [Tree(NP, [Tree(A, ['colorless']), Tree(NP, [Tree(A, ['green']), Tree(N, ['ideas'])])]), Tree(VP, [Tree(V, ['sleep']), Tree(Adv, ['furiously'])])])]\n",
            "(S\n",
            "  (NP (A colorless) (NP (A green) (N ideas)))\n",
            "  (VP (V sleep) (Adv furiously)))\n",
            "The sentence 'colorless green ideas sleep furiously' can be generated by the grammar\n",
            "                      S                      \n",
            "             _________|__________             \n",
            "            NP                   |           \n",
            "     _______|____                |            \n",
            "    |            NP              VP          \n",
            "    |        ____|____       ____|______      \n",
            "    A       A         N     V          Adv   \n",
            "    |       |         |     |           |     \n",
            "colorless green     ideas sleep     furiously\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def cky(words, flipped_grammar):\n",
        "    len_1 = len(words) + 1\n",
        "    #table initialisation\n",
        "    table = [[[] for _ in range(len_1)] for _ in range(len_1)]  # Corrected table initialization\n",
        "\n",
        "    # Fill in the terminal rules\n",
        "    for col in range(1, len_1):\n",
        "        word = words[col - 1]\n",
        "        col_tuple = (word,)  # Using tuple directly\n",
        "        if col_tuple in flipped_grammar:\n",
        "            for symbol in flipped_grammar[col_tuple]:\n",
        "                table[col - 1][col].append(Tree(symbol, [word]))\n",
        "    # Filling in the grammar rules\n",
        "    for col in range(1, len_1):\n",
        "        for row in range(col - 1, -1, -1):\n",
        "            for pivot in range(row + 1, col):\n",
        "                for subset1 in table[row][pivot]:\n",
        "                    for subset2 in table[pivot][col]:\n",
        "                        rhs = (subset1.label(), subset2.label())\n",
        "                        if rhs in flipped_grammar:\n",
        "                            for left_symbol in flipped_grammar[rhs]:\n",
        "                                table[row][col].append(Tree(left_symbol, [subset1, subset2]))\n",
        "            print(f\"Filled table[{row}][{col}]: {table[row][col]}\")\n",
        "\n",
        "        trees = table[0][-1]\n",
        "    for tree in trees:\n",
        "        print(tree.pformat())\n",
        "    return trees\n",
        "\n",
        "words = word_tokenize('colorless green ideas sleep furiously')\n",
        "parsing_trees = cky(words, flipped_grammar)\n",
        "\n",
        "if parsing_trees:\n",
        "    print(f\"The sentence '{' '.join(words)}' can be generated by the grammar\")\n",
        "else:\n",
        "    print(f\"The sentence '{' '.join(words)}' cannot be generated by the grammar\")\n",
        "\n",
        "tree = Tree.fromstring(str(parsing_trees[0]))\n",
        "tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CKY is efficient for grammars in CNF since it operates in `O(n^3)` time, with `n` the number of words in the sentence."
      ],
      "metadata": {
        "id": "DrBuUuu0SGeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Earley algorithm**"
      ],
      "metadata": {
        "id": "dRDxJiaXVYdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Earley Algorithm\n",
        "\n",
        "The **Earley parser** is an algorithm designed for parsing sentences using context-free grammars, which can handle a wide range of language structures, including ambiguous and recursive grammars. It builds a chart (a dynamic programming table) where each entry tracks the parsing progress at a certain point in the input sentence.\n",
        "\n",
        "#### **Working of the Algorithm:**\n",
        "\n",
        "1. **State**: Each state in the chart represents a step in the parsing process. It consists of:\n",
        "   - **Label**: A non-terminal.\n",
        "   - **Rules**: The current production rule being processed.\n",
        "   - **Dot (•)**: Marks the current position in the production rule. The dot indicates what has been processed and what remains.\n",
        "   - **Start and End indices**: The range in the input sentence this rule applies to.\n",
        "   - **Made from**: The state this state was derived from (used for backtracking in parsing).\n",
        "   - **Producer**: How the state was created (predictor, scanner, completer).\n",
        "\n",
        "2. **Operations**:\n",
        "   - **Predictor**: Adds possible expansions for non-terminals.\n",
        "   - **Scanner**: Matches terminals (words from the input sentence).\n",
        "   - **Completer**: Combines parsed structures when non-terminals are completed."
      ],
      "metadata": {
        "id": "jQ6NRnuR8iPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base case implementation of the Earley algorithm\n"
      ],
      "metadata": {
        "id": "ceMyhq_p_gPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample grammar"
      ],
      "metadata": {
        "id": "vJHPJm_47Qc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_grammar = {\n",
        "    '<start>': [['<A>','<B>']],\n",
        "    '<A>': [['a', '<B>', 'c'], ['a', '<A>']],\n",
        "    '<B>': [['b', '<C>'], ['<D>']],\n",
        "    '<C>': [['c']],\n",
        "    '<D>': [['d']]\n",
        "}\n"
      ],
      "metadata": {
        "id": "hbOD5xkz7hS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Column Data structure"
      ],
      "metadata": {
        "id": "FKJb0Jt7ziSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Column:\n",
        "  def __init__(self, index, letter):\n",
        "    self.index, self.letter = index, letter\n",
        "    self.states, self._unique = [], {}\n",
        "  def __str__(self):\n",
        "    return \"% chart[%d]\\n%s\" % (self.letter, self.index, \"\\n\".join(\n",
        "        str(state) for state in self.states if state.finished()))\n",
        "  def to_repr(self):\n",
        "    return \"%s chart[%d]\\n%s\" % (self.letter, self.index, \"\\n\".join(\n",
        "        str(state) for state in self.states))\n",
        "  def add(self, state):\n",
        "    if state in self._unique:\n",
        "      return self._unique[state]\n",
        "    self._unique[state] = state\n",
        "    self.states.append(state)\n",
        "    return self._unique[state]\n"
      ],
      "metadata": {
        "id": "JMv3anUVChIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The State Data Structure"
      ],
      "metadata": {
        "id": "ngLPlTHezvrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "  def __init__(self, name, expr, dot, s_col, e_col=None):\n",
        "    self.name, self.expr, self.dot = name, expr, dot\n",
        "    self.s_col, self.e_col = s_col, e_col\n",
        "\n",
        "  def finished(self):\n",
        "    return self.dot >= len(self.expr)\n",
        "\n",
        "  def at_dot(self):\n",
        "    return self.expr[self.dot] if self.dot < len(self.expr) else None\n",
        "\n",
        "  def __str__(self):\n",
        "    def idx(var):\n",
        "      return var.index if var else -1\n",
        "    return show_dot(self.name, self.expr, self.dot)\n",
        "\n",
        "  def copy(self):\n",
        "    return State(self.name, self.expr, self.dot, self.s_col.index)\n",
        "\n",
        "  def _t(self):\n",
        "    return(self.name, self.expr, self.dot, self.s_col.index)\n",
        "\n",
        "  def __hash__(self):\n",
        "    return hash(self._t())\n",
        "\n",
        "  def __eq__(self, other):\n",
        "    return self.t()== other._t()\n",
        "\n",
        "  def advance(self):\n",
        "    return State(self.name, self.expr, self.dot + 1, self.s_col)\n",
        "\n",
        "def show_dot(sym, rule, pos, dotstr= \"|\", extents=''):\n",
        "  extends = str(extents)\n",
        "  return sym + '::=' + ' '.join([\n",
        "      str(p)\n",
        "      for p in [*rule[0:pos], dotstr, *rule[pos:]]]) + extents\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SaKN7G12xUA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The parser is able to move from B to D (bellow) which is the next logical step according to the sample grammar"
      ],
      "metadata": {
        "id": "oe3_CEWpF1P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nt_name = '<B>'\n",
        "nt_expr = tuple(sample_grammar[nt_name][1])\n",
        "col_0 = Column(0, None)\n",
        "a_state = State(nt_name, tuple(nt_expr), 0, col_0)\n",
        "print(a_state.at_dot())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YMPZRG3IWY",
        "outputId": "2fd2ce52-bf06-4fe3-8620-7c2be45af8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<D>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementation of Earley Parsing algorithm general case**"
      ],
      "metadata": {
        "id": "ZEl13VA4HtaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "  #  initializing a new State object with its properties\n",
        "  # This class represents a single state in the Earley chart\n",
        "  def __init__(self, label, rules, dot_idx, start_idx, end_idx, idx, made_from, producer):\n",
        "    self.label = label # The non-terminal symbol on the left hand side of the rule\n",
        "    self.rules = rules #\n",
        "    self.dot_idx = dot_idx # Position of the dot in the dot in the rule (progress)\n",
        "    self.start_idx = start_idx # Start position of the rule in the sentence\n",
        "    self.end_idx = end_idx # End position of the rule\n",
        "    self.idx = idx # Unique id for the state\n",
        "    self.made_from = made_from # List of states derived from previous state\n",
        "    self.producer = producer # Operation that create the state\n",
        "\n",
        "  def next(self):\n",
        "    \"\"\"Returns the tag of the dot\"\"\"\n",
        "    if self.dot_idx < len(self.rules):\n",
        "      return self.rules[self.dot_idx]\n",
        "    return None\n",
        "\n",
        "  # Checks if the state is complete (dot(bullet) is at the end of the rule)\n",
        "  def complete(self):\n",
        "    return len(self.rules) == self.dot_idx\n",
        "  # Compare two State objects for equality\n",
        "  def __eq__(self, other):\n",
        "    return (self.label == other.label and\n",
        "            self.rules == other.rules and\n",
        "            self.dot_idx == other.dot_idx and\n",
        "            self.start_idx == other.start_idx and\n",
        "            self.end_idx == other.end_idx)\n",
        "\n",
        "  # represent a Stste object as a string\n",
        "  def __str__(self):\n",
        "    rule_string = ''\n",
        "    for i, rule in enumerate(self.rules):\n",
        "      if i == self.dot_idx:\n",
        "          rule_string += '• '\n",
        "      rule_string += rule + ' '\n",
        "    if self.dot_idx == len(self.rules):\n",
        "      rule_string += '• '\n",
        "    return 'S%d %s -> %s [%d, %d] %s %s' % (self.idx, self.label, rule_string, self.start_idx,\n",
        "                                            self.end_idx, self.made_from, self.producer)\n",
        "\n",
        "# Earley logic implementation\n",
        "class Earley:\n",
        "  def __init__(self, words, grammar, terminals):\n",
        "    self.chart = [[] for _ in range(len(words) + 1)]\n",
        "    self.current_id = 0\n",
        "    self.words = words # input sentence as a list of words\n",
        "    self.grammar = grammar # Arbritrary grammar rules\n",
        "    self.terminals = terminals # list of terminals in the grammar\n",
        "\n",
        "  def get_new_id(self):\n",
        "    self.current_id += 1\n",
        "    return self.current_id -1\n",
        "\n",
        "  def is_terminal(self, tag):\n",
        "    return tag in self.terminals\n",
        "\n",
        "  def is_complete(self, state):\n",
        "    return len(state.rules) ==  state.dot_idx\n",
        "\n",
        "  def enqueue(self, state, chart_entry):\n",
        "    if state not in self.chart[chart_entry]:\n",
        "      self.chart[chart_entry].append(state)\n",
        "    else:\n",
        "      self.current_id -= 1\n",
        "\n",
        "  def predictor(self, state):\n",
        "    next_item = state.next()\n",
        "    if next_item in self.grammar:\n",
        "      for production in self.grammar[next_item]:\n",
        "        self.enqueue(State(state.next(), production, 0, state.end_idx, state.end_idx, self.get_new_id(), [], 'predictor'), state.end_idx)\n",
        "\n",
        "  def scanner(self, state):\n",
        "    if self.words[state.end_idx] in self.grammar[state.next()]:\n",
        "        self.enqueue(State(state.next(), [self.words[state.end_idx]], 1, state.end_idx, state.end_idx + 1, self.get_new_id(), [], 'scanner'), state.end_idx + 1)\n",
        "\n",
        "  def completer(self, state):\n",
        "    for s in self.chart[state.start_idx]:\n",
        "      if not s.complete() and s.next() == state.label and s.end_idx == state.start_idx and s.label != 'gamma':\n",
        "        self.enqueue(State(s.label, s.rules, s.dot_idx + 1, s.start_idx, state.end_idx, self.get_new_id(), s.made_from + [state.idx], 'completer'), state.end_idx)\n",
        "\n",
        "  def parse(self):\n",
        "    self.enqueue(State('gamma', ['S'], 0, 0, 0, self.get_new_id(), [], 'dummy start state'),0)\n",
        "\n",
        "    for i in range(len(self.words)+ 1):\n",
        "      for state in self.chart[i]:\n",
        "        if not state.complete() and not self.is_terminal(state.next()):\n",
        "          self.predictor(state)\n",
        "        elif i != len(self.words) and not state.complete() and self.is_terminal(state.next()):\n",
        "          self.scanner(state)\n",
        "        else:\n",
        "          self.completer(state)\n",
        "\n",
        "  def __str__(self):\n",
        "      res = ' '\n",
        "\n",
        "      for i, chart in enumerate(self.chart):\n",
        "        res += '\\nChart[%d]\\n' % i\n",
        "        for state in chart:\n",
        "          res += str(state) + '\\n'\n",
        "\n",
        "      return res\n"
      ],
      "metadata": {
        "id": "3CY85UgB-z54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text():\n",
        "\n",
        "  grammar = {\n",
        "        'S':           [['NP', 'VP'], ['Aux', 'NP', 'VP'], ['VP']],\n",
        "        'NP':          [['Det', 'Nominal'], ['Proper-Noun']],\n",
        "        'Nominal':     [['Noun'], ['Noun', 'Nominal']],\n",
        "        'VP':          [['Verb'], ['Verb', 'NP']],\n",
        "        'Det':         ['the', 'a'],\n",
        "        'Noun':        ['dog', 'cat', 'book', 'flight'],\n",
        "        'Verb':        ['sees', 'chases', 'book'],\n",
        "        'Aux':         ['does'],\n",
        "        'Proper-Noun': ['Houston', 'TWA']\n",
        "  }\n",
        "\n",
        "  terminals = ['Det', 'Noun', 'Verb', 'Aux', 'Proper-Noun']\n",
        "\n",
        "  words = ['the', 'dog', 'sees', 'the', 'cat']\n",
        "\n",
        "  earley = Earley(words, grammar, terminals)\n",
        "  earley.parse()\n",
        "  print(earley)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oec_sC4RNhSK",
        "outputId": "19dabdaf-2551-427a-f6d7-64cc6e675c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Chart[0]\n",
            "S0 gamma -> • S  [0, 0] [] dummy start state\n",
            "S1 S -> • NP VP  [0, 0] [] predictor\n",
            "S2 S -> • Aux NP VP  [0, 0] [] predictor\n",
            "S3 S -> • VP  [0, 0] [] predictor\n",
            "S4 NP -> • Det Nominal  [0, 0] [] predictor\n",
            "S5 NP -> • Proper-Noun  [0, 0] [] predictor\n",
            "S6 VP -> • Verb  [0, 0] [] predictor\n",
            "S7 VP -> • Verb NP  [0, 0] [] predictor\n",
            "\n",
            "Chart[1]\n",
            "S8 Det -> the •  [0, 1] [] scanner\n",
            "S9 NP -> Det • Nominal  [0, 1] [8] completer\n",
            "S10 Nominal -> • Noun  [1, 1] [] predictor\n",
            "S11 Nominal -> • Noun Nominal  [1, 1] [] predictor\n",
            "\n",
            "Chart[2]\n",
            "S12 Noun -> dog •  [1, 2] [] scanner\n",
            "S13 Nominal -> Noun •  [1, 2] [12] completer\n",
            "S14 Nominal -> Noun • Nominal  [1, 2] [12] completer\n",
            "S15 NP -> Det Nominal •  [0, 2] [8, 13] completer\n",
            "S16 Nominal -> • Noun  [2, 2] [] predictor\n",
            "S17 Nominal -> • Noun Nominal  [2, 2] [] predictor\n",
            "S18 S -> NP • VP  [0, 2] [15] completer\n",
            "S19 VP -> • Verb  [2, 2] [] predictor\n",
            "S20 VP -> • Verb NP  [2, 2] [] predictor\n",
            "\n",
            "Chart[3]\n",
            "S21 Verb -> sees •  [2, 3] [] scanner\n",
            "S22 VP -> Verb •  [2, 3] [21] completer\n",
            "S23 VP -> Verb • NP  [2, 3] [21] completer\n",
            "S24 S -> NP VP •  [0, 3] [15, 22] completer\n",
            "S25 NP -> • Det Nominal  [3, 3] [] predictor\n",
            "S26 NP -> • Proper-Noun  [3, 3] [] predictor\n",
            "\n",
            "Chart[4]\n",
            "S27 Det -> the •  [3, 4] [] scanner\n",
            "S28 NP -> Det • Nominal  [3, 4] [27] completer\n",
            "S29 Nominal -> • Noun  [4, 4] [] predictor\n",
            "S30 Nominal -> • Noun Nominal  [4, 4] [] predictor\n",
            "\n",
            "Chart[5]\n",
            "S31 Noun -> cat •  [4, 5] [] scanner\n",
            "S32 Nominal -> Noun •  [4, 5] [31] completer\n",
            "S33 Nominal -> Noun • Nominal  [4, 5] [31] completer\n",
            "S34 NP -> Det Nominal •  [3, 5] [27, 32] completer\n",
            "S35 Nominal -> • Noun  [5, 5] [] predictor\n",
            "S36 Nominal -> • Noun Nominal  [5, 5] [] predictor\n",
            "S37 VP -> Verb NP •  [2, 5] [21, 34] completer\n",
            "S38 Nominal -> Noun Nominal •  [4, 5] [31, 35] completer\n",
            "S39 S -> NP VP •  [0, 5] [15, 37] completer\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Chart Breakdown:**\n",
        "\n",
        "Each chart represents the state of parsing at a particular position in the input sentence. The goal is to track the parsing progress using a sequence of states in these charts.\n",
        "\n",
        "### **Chart[0]**\n"
      ],
      "metadata": {
        "id": "ePdAuqJx8TU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart[0]\n",
        "S0 gamma -> • S  [0, 0] [ ] dummy start state  \n",
        "S1 S -> • NP VP  [0, 0] [ ] predictor  \n",
        "S2 S -> • Aux NP VP  [0, 0] [] predictor  \n",
        "S3 S -> • VP  [0, 0] [ ] predictor  \n",
        "S4 NP -> • Det Nominal  [0, 0] [ ] predictor  \n",
        "S5 NP -> • Proper-Noun  [0, 0] [ ] predictor  \n",
        "S6 VP -> • Verb  [0, 0] [ ] predictor  \n",
        "S7 VP -> • Verb NP  [0, 0] [ ] predictor"
      ],
      "metadata": {
        "id": "M230hMnXJ3OI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Chart[0]** shows the initial prediction phase (`predictor`), where the parser expands possible rules that could start the sentence. `S -> NP VP`, `S -> VP` and `Aux NP VP` represent possible sentence structures.\n",
        "- The dummy start state `S0 gamma -> bullet S` is used to initialize the parsing process.\n",
        "\n",
        "### **Chart[1]**\n",
        "S8 Det -> the •  [0, 1] [ ] scanner  \n",
        "S9 NP -> Det • Nominal  [0, 1] [8] completer  \n",
        "S10 Nominal -> • Noun  [1, 1] [ ] predictor  \n",
        "S11 Nominal -> • Noun Nominal  [1, 1] [ ] predictor"
      ],
      "metadata": {
        "id": "gsyzVqU5IVHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Chart[1]** shows the effect of reading the first word `the` (`scanner`). After scanning `the`, the state `Det -> the •` moves the dot past `the`, indicating this terminal has been successfully matched.\n",
        "- Next, the parser predicts that the `NP` (noun phrase) continues with `Nominal`, so the dot moves forward in `NP -> Det Nominal`.\n",
        "\n",
        "### **Chart[2]**\n",
        "S12 Noun -> dog •  [1, 2] [ ] scanner  \n",
        "S13 Nominal -> Noun •  [1, 2] [12] completer  \n",
        "S14 Nominal -> Noun • Nominal  [1, 2] [12] completer  \n",
        "S15 NP -> Det Nominal •  [0, 2] [8, 13] completer  \n",
        "S16 Nominal -> • Noun  [2, 2] [ ] predictor  \n",
        "S17 Nominal -> • Noun Nominal  [2, 2] [ ] predictor  \n",
        "S18 S -> NP • VP  [0, 2] [15] completer  \n",
        "S19 VP -> • Verb  [2, 2] [ ] predictor  \n",
        "S20 VP -> • Verb NP  [2, 2] [ ] predictor"
      ],
      "metadata": {
        "id": "s_3tOSdEI-Ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Chart[2]** continues after matching `dog`. This is processed by the scanner (`Noun -> dog •`), and now we can mark the `NP -> Det Nominal` as complete, since both `Det` and `Nominal` have been parsed.\n",
        "- Now the parser predicts the next part of the sentence, such as expecting a verb phrase (`VP`).\n",
        "\n",
        "### **Chart[3]**\n",
        "\n",
        "\n",
        "S21 Verb -> sees •  [2, 3] [ ] scanner  \n",
        "S22 VP -> Verb •  [2, 3] [21] completer  \n",
        "S23 VP -> Verb • NP  [2, 3] [21] completer  \n",
        "S24 S -> NP VP •  [0, 3] [15, 22] completer  \n",
        "S25 NP -> • Det Nominal  [3, 3] [ ] predictor  \n",
        "S26 NP -> • Proper-Noun  [3, 3] [ ] predictor"
      ],
      "metadata": {
        "id": "v5qsYVRPI3CI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Chart[3]** completes the verb `sees` (`Verb -> sees •`) and moves forward to complete `VP -> Verb`.\n",
        "- The sentence `S -> NP VP` is now complete, indicating that up to this point, the phrase `the dog sees` is valid.\n",
        "- The parser also predicts possible noun phrases (`NP -> Det Nominal`) starting at position 3.\n",
        "\n",
        "### **Chart[4]**\n",
        "\n",
        "S27 Det -> the •  [3, 4] [ ] scanner  \n",
        "S28 NP -> Det • Nominal  [3, 4] [27] completer  \n",
        "S29 Nominal -> • Noun  [4, 4] [ ] predictor  \n",
        "S30 Nominal -> • Noun Nominal  [4, 4] [ ] predictor  "
      ],
      "metadata": {
        "id": "q4QDtjvBJA9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Chart[4]** handles the next noun phrase, starting with `the` (`Det -> the •`). The parser continues predicting the next part of the noun phrase (`NP -> Det Nominal`).\n",
        "\n",
        "### **Chart[5]**\n",
        "\n",
        "S31 Noun -> cat •  [4, 5] [ ] scanner  \n",
        "S32 Nominal -> Noun •  [4, 5] [31] completer  \n",
        "S33 Nominal -> Noun • Nominal  [4, 5] [31] completer  \n",
        "S34 NP -> Det Nominal •  [3, 5] [27, 32] completer  \n",
        "S35 Nominal -> • Noun  [5, 5] [ ] predictor  \n",
        "S36 Nominal -> • Noun Nominal  [5, 5] [ ] predictor  \n",
        "S37 VP -> Verb NP •  [2, 5] [21, 34] completer  \n",
        "S38 Nominal -> Noun Nominal •  [4, 5] [31, 35] completer  \n",
        "S39 S -> NP VP •  [0, 5] [15, 37] completer"
      ],
      "metadata": {
        "id": "rFekhemIJJkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Chart[5]** finishes parsing the phrase `the cat` (`Noun -> cat •`), completing the noun phrase `Det Nominal`.\n",
        "- The entire sentence `the dog sees the cat` is now parsed and completed (`S -> NP VP •`), marking the end of the successful parse.\n"
      ],
      "metadata": {
        "id": "78smppPBJkOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Chart entries** represent the parser's progress, with the dot (`•`) indicating what part of the rule has been parsed.\n",
        "- The **predictor** expands non-terminals to explore possible future rules.\n",
        "- The **scanner** matches terminals (words in the input).\n",
        "- The **completer** combines parsed subcomponents once a rule is fully matched.\n",
        "- The goal is to complete a rule from the start symbol (`S`) covering the entire sentence (`gamma -> S •`), indicating that the sentence is valid according to the grammar."
      ],
      "metadata": {
        "id": "DOJ4uTwJJriU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Earley Algorithm vs. CKY Algorithm\n",
        "\n",
        "Both the **Earley** and **CKY** algorithms are parsing techniques used to determine whether a given sentence can be generated by a context-free grammar (CFG). However, they differ in terms of their approach, efficiency, and the types of grammars they can handle.\n",
        "\n",
        "#### 1. **Differences**\n",
        "\n",
        "- **Earley Algorithm**:\n",
        "  - **Generalization**: Earley is a **general parsing algorithm** that can handle any context-free grammar, including ambiguous and non-CNF grammars. This makes it highly versatile.\n",
        "  - **Efficiency**: It operates in **O(n^3)** time in the worst case, but for many grammars, especially those that are unambiguous, it can perform better in practice.\n",
        "  - **Structure**: It uses a predictive parsing strategy, maintaining a chart of possible parses that evolves as the input is processed.\n",
        "\n",
        "- **CKY Algorithm**:\n",
        "  - **Specificity**: CKY is restricted to parsing **grammars in Chomsky Normal Form (CNF)**. This limits its applicability but also makes it simpler and more efficient for certain types of grammars.\n",
        "  - **Efficiency**: The algorithm operates in **O(n^3)** time and is often faster than Earley for CNF grammars, especially when the grammar is not too complex.\n",
        "  - **Table-based**: It builds a parsing table using dynamic programming, making it suitable for well-defined grammars.\n",
        "\n",
        "#### 2. **Use Cases**\n",
        "\n",
        "- **Earley Algorithm**:\n",
        "  - Suitable for grammars that are ambiguous or not in CNF.\n",
        "  - Ideal for natural language processing tasks where grammars may not be strictly defined.\n",
        "\n",
        "- **CKY Algorithm**:\n",
        "  - Best suited for formal grammars that can easily be converted into CNF.\n",
        "  - Efficient for parsing in environments where grammar structure is strictly controlled."
      ],
      "metadata": {
        "id": "R340NUQmTt1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complex_sentence = \"The quick brown fox jumps over the lazy dog while the cat watches carefully\"\n",
        "\n",
        "def text():\n",
        "    grammar = {\n",
        "        'S':           [['NP', 'VP'], ['S', 'Conj', 'S']],\n",
        "        'NP':          [['Det', 'Nominal'], ['A', 'Nominal']],\n",
        "        'Nominal':     [['Noun'], ['A', 'Nominal']],\n",
        "        'VP':          [['Verb', 'Adv'], ['Verb', 'NP'], ['Verb', 'PP'], ['Verb', 'NP', 'Adv']],\n",
        "        'PP':          [['P', 'NP']],\n",
        "        'A':           ['quick', 'brown', 'lazy'],\n",
        "        'Det':         ['the', 'a'],\n",
        "        'Noun':        ['dog', 'cat', 'fox'],\n",
        "        'Verb':        ['jumps', 'watches'],\n",
        "        'P':           ['over'],\n",
        "        'Conj':        ['while'],\n",
        "        'Adv':         ['carefully'],\n",
        "    }\n",
        "\n",
        "    terminals = ['Det', 'Noun', 'Verb', 'Aux', 'Proper-Noun','A', 'P', 'carefully', 'Conj', 'Adv']\n",
        "\n",
        "    words = ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'while', 'the', 'cat', 'watches', 'carefully']\n",
        "\n",
        "    earley = Earley(words, grammar, terminals)\n",
        "    parsing_result = earley.parse()\n",
        "    print(earley)\n",
        "if __name__ == '__main__':\n",
        "    text()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7O8R5NAZBXd",
        "outputId": "3f68f1b6-978c-4aa9-c1a9-e388527a1185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Chart[0]\n",
            "S0 gamma -> • S  [0, 0] [] dummy start state\n",
            "S1 S -> • NP VP  [0, 0] [] predictor\n",
            "S2 S -> • S Conj S  [0, 0] [] predictor\n",
            "S3 NP -> • Det Nominal  [0, 0] [] predictor\n",
            "S4 NP -> • A Nominal  [0, 0] [] predictor\n",
            "\n",
            "Chart[1]\n",
            "S5 Det -> the •  [0, 1] [] scanner\n",
            "S6 NP -> Det • Nominal  [0, 1] [5] completer\n",
            "S7 Nominal -> • Noun  [1, 1] [] predictor\n",
            "S8 Nominal -> • A Nominal  [1, 1] [] predictor\n",
            "\n",
            "Chart[2]\n",
            "S9 A -> quick •  [1, 2] [] scanner\n",
            "S10 Nominal -> A • Nominal  [1, 2] [9] completer\n",
            "S11 Nominal -> • Noun  [2, 2] [] predictor\n",
            "S12 Nominal -> • A Nominal  [2, 2] [] predictor\n",
            "\n",
            "Chart[3]\n",
            "S13 A -> brown •  [2, 3] [] scanner\n",
            "S14 Nominal -> A • Nominal  [2, 3] [13] completer\n",
            "S15 Nominal -> • Noun  [3, 3] [] predictor\n",
            "S16 Nominal -> • A Nominal  [3, 3] [] predictor\n",
            "\n",
            "Chart[4]\n",
            "S17 Noun -> fox •  [3, 4] [] scanner\n",
            "S18 Nominal -> Noun •  [3, 4] [17] completer\n",
            "S19 Nominal -> A Nominal •  [2, 4] [13, 18] completer\n",
            "S20 Nominal -> A Nominal •  [1, 4] [9, 19] completer\n",
            "S21 NP -> Det Nominal •  [0, 4] [5, 20] completer\n",
            "S22 S -> NP • VP  [0, 4] [21] completer\n",
            "S23 VP -> • Verb Adv  [4, 4] [] predictor\n",
            "S24 VP -> • Verb NP  [4, 4] [] predictor\n",
            "S25 VP -> • Verb PP  [4, 4] [] predictor\n",
            "S26 VP -> • Verb NP Adv  [4, 4] [] predictor\n",
            "\n",
            "Chart[5]\n",
            "S27 Verb -> jumps •  [4, 5] [] scanner\n",
            "S28 VP -> Verb • Adv  [4, 5] [27] completer\n",
            "S29 VP -> Verb • NP  [4, 5] [27] completer\n",
            "S30 VP -> Verb • PP  [4, 5] [27] completer\n",
            "S31 VP -> Verb • NP Adv  [4, 5] [27] completer\n",
            "S32 NP -> • Det Nominal  [5, 5] [] predictor\n",
            "S33 NP -> • A Nominal  [5, 5] [] predictor\n",
            "S34 PP -> • P NP  [5, 5] [] predictor\n",
            "\n",
            "Chart[6]\n",
            "S35 P -> over •  [5, 6] [] scanner\n",
            "S36 PP -> P • NP  [5, 6] [35] completer\n",
            "S37 NP -> • Det Nominal  [6, 6] [] predictor\n",
            "S38 NP -> • A Nominal  [6, 6] [] predictor\n",
            "\n",
            "Chart[7]\n",
            "S39 Det -> the •  [6, 7] [] scanner\n",
            "S40 NP -> Det • Nominal  [6, 7] [39] completer\n",
            "S41 Nominal -> • Noun  [7, 7] [] predictor\n",
            "S42 Nominal -> • A Nominal  [7, 7] [] predictor\n",
            "\n",
            "Chart[8]\n",
            "S43 A -> lazy •  [7, 8] [] scanner\n",
            "S44 Nominal -> A • Nominal  [7, 8] [43] completer\n",
            "S45 Nominal -> • Noun  [8, 8] [] predictor\n",
            "S46 Nominal -> • A Nominal  [8, 8] [] predictor\n",
            "\n",
            "Chart[9]\n",
            "S47 Noun -> dog •  [8, 9] [] scanner\n",
            "S48 Nominal -> Noun •  [8, 9] [47] completer\n",
            "S49 Nominal -> A Nominal •  [7, 9] [43, 48] completer\n",
            "S50 NP -> Det Nominal •  [6, 9] [39, 49] completer\n",
            "S51 PP -> P NP •  [5, 9] [35, 50] completer\n",
            "S52 VP -> Verb PP •  [4, 9] [27, 51] completer\n",
            "S53 S -> NP VP •  [0, 9] [21, 52] completer\n",
            "S54 S -> S • Conj S  [0, 9] [53] completer\n",
            "\n",
            "Chart[10]\n",
            "S55 Conj -> while •  [9, 10] [] scanner\n",
            "S56 S -> S Conj • S  [0, 10] [53, 55] completer\n",
            "S57 S -> • NP VP  [10, 10] [] predictor\n",
            "S58 S -> • S Conj S  [10, 10] [] predictor\n",
            "S59 NP -> • Det Nominal  [10, 10] [] predictor\n",
            "S60 NP -> • A Nominal  [10, 10] [] predictor\n",
            "\n",
            "Chart[11]\n",
            "S61 Det -> the •  [10, 11] [] scanner\n",
            "S62 NP -> Det • Nominal  [10, 11] [61] completer\n",
            "S63 Nominal -> • Noun  [11, 11] [] predictor\n",
            "S64 Nominal -> • A Nominal  [11, 11] [] predictor\n",
            "\n",
            "Chart[12]\n",
            "S65 Noun -> cat •  [11, 12] [] scanner\n",
            "S66 Nominal -> Noun •  [11, 12] [65] completer\n",
            "S67 NP -> Det Nominal •  [10, 12] [61, 66] completer\n",
            "S68 S -> NP • VP  [10, 12] [67] completer\n",
            "S69 VP -> • Verb Adv  [12, 12] [] predictor\n",
            "S70 VP -> • Verb NP  [12, 12] [] predictor\n",
            "S71 VP -> • Verb PP  [12, 12] [] predictor\n",
            "S72 VP -> • Verb NP Adv  [12, 12] [] predictor\n",
            "\n",
            "Chart[13]\n",
            "S73 Verb -> watches •  [12, 13] [] scanner\n",
            "S74 VP -> Verb • Adv  [12, 13] [73] completer\n",
            "S75 VP -> Verb • NP  [12, 13] [73] completer\n",
            "S76 VP -> Verb • PP  [12, 13] [73] completer\n",
            "S77 VP -> Verb • NP Adv  [12, 13] [73] completer\n",
            "S79 NP -> • Det Nominal  [13, 13] [] predictor\n",
            "S80 NP -> • A Nominal  [13, 13] [] predictor\n",
            "S81 PP -> • P NP  [13, 13] [] predictor\n",
            "\n",
            "Chart[14]\n",
            "S78 Adv -> carefully •  [13, 14] [] scanner\n",
            "S82 VP -> Verb Adv •  [12, 14] [73, 78] completer\n",
            "S83 S -> NP VP •  [10, 14] [67, 82] completer\n",
            "S84 S -> S Conj S •  [0, 14] [53, 55, 83] completer\n",
            "S85 S -> S • Conj S  [10, 14] [83] completer\n",
            "S86 S -> S • Conj S  [0, 14] [84] completer\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag\n",
        "sample_text = \"the quick brown fox jumps over the lazy dog while the cat watches carefully\"\n",
        "token = word_tokenize(sample_text)\n",
        "tagged = pos_tag(token)\n",
        "tagged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4EPR422lZgr",
        "outputId": "b8e8b4f1-4050-4d43-ef67-8ec8c2cd1672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 'DT'),\n",
              " ('quick', 'JJ'),\n",
              " ('brown', 'NN'),\n",
              " ('fox', 'NN'),\n",
              " ('jumps', 'VBZ'),\n",
              " ('over', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('lazy', 'JJ'),\n",
              " ('dog', 'NN'),\n",
              " ('while', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('cat', 'NN'),\n",
              " ('watches', 'NNS'),\n",
              " ('carefully', 'RB')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  S -> S Sub S\n",
        "  NP -> D N2\n",
        "  N2 -> Adj N2\n",
        "  N2 -> N\n",
        "  VP -> V NP\n",
        "  VP -> V PP\n",
        "  VP -> V AdvP\n",
        "  PP -> P NP\n",
        "  AdvP -> Adv\n",
        "  Sub -> 'while'\n",
        "  D -> 'the'\n",
        "  Adj -> 'quick'\n",
        "  Adj -> 'brown'\n",
        "  Adj -> 'lazy'\n",
        "  N -> 'fox'\n",
        "  N -> 'dog'\n",
        "  N -> 'cat'\n",
        "  V -> 'jumps'\n",
        "  V -> 'watches'\n",
        "  P -> 'over'\n",
        "  Adv -> 'carefully'\n",
        "\"\"\")\n",
        "\n",
        "flipped_grammar = get_flipped_grammar(grammar)\n",
        "\n",
        "\n",
        "words = word_tokenize('the quick brown fox jumps over the lazy dog while the cat watches carefully')\n",
        "parsing_trees = cky(words, flipped_grammar)\n",
        "\n",
        "if parsing_trees:\n",
        "    print(f\"The sentence '{' '.join(words)}' can be generated by the grammar\")\n",
        "else:\n",
        "    print(f\"The sentence '{' '.join(words)}' cannot be generated by the grammar\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PA74PilCGyGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "# Create a context-free grammar\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  S -> S Sub S\n",
        "  NP -> D N2\n",
        "  N2 -> Adj N2\n",
        "  N2 -> N\n",
        "  VP -> V NP\n",
        "  VP -> V PP\n",
        "  VP -> V AdvP\n",
        "  PP -> P NP\n",
        "  AdvP -> Adv\n",
        "  Sub -> 'while'\n",
        "  D -> 'the'\n",
        "  Adj -> 'quick'\n",
        "  Adj -> 'brown'\n",
        "  Adj -> 'lazy'\n",
        "  N -> 'fox'\n",
        "  N -> 'dog'\n",
        "  N -> 'cat'\n",
        "  V -> 'jumps'\n",
        "  V -> 'watches'\n",
        "  P -> 'over'\n",
        "  Adv -> 'carefully'\n",
        "\"\"\")\n",
        "parser = nltk.ChartParser(grammar)\n",
        "sentence = \"the quick brown fox jumps over the lazy dog while the cat watches carefully\".split()\n",
        "\n",
        "# Parse the sentence\n",
        "trees = list(parser.parse(sentence))\n",
        "\n",
        "if trees:\n",
        "    print(\"Parsing successful!\")\n",
        "    for tree in trees:\n",
        "        print(tree)\n",
        "else:\n",
        "    print(\"Parsing failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBPHMqzlD29I",
        "outputId": "4acaeba8-65a5-4178-8083-92f7fbd2db62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing successful!\n",
            "(S\n",
            "  (S\n",
            "    (NP (D the) (N2 (Adj quick) (N2 (Adj brown) (N2 (N fox)))))\n",
            "    (VP\n",
            "      (V jumps)\n",
            "      (PP (P over) (NP (D the) (N2 (Adj lazy) (N2 (N dog)))))))\n",
            "  (Sub while)\n",
            "  (S\n",
            "    (NP (D the) (N2 (N cat)))\n",
            "    (VP (V watches) (AdvP (Adv carefully)))))\n"
          ]
        }
      ]
    }
  ]
}